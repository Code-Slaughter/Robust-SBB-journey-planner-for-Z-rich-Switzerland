{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "776ff5a7-a169-44a7-9661-3557573ea554",
   "metadata": {},
   "source": [
    "# Set up spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "794f2c5b-b980-469b-b0a7-4f40f14edce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d76a9793-1dbb-4d2b-ab9e-f7cccbfdd985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "\n",
    "# set the application name as \"<your_gaspar_id>-homework3\"\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "server = \"http://iccluster029.iccluster.epfl.ch:8998\"\n",
    "\n",
    "get_ipython().run_cell_magic(\n",
    "    'spark',\n",
    "    line='config', \n",
    "    cell=\"\"\"{{ \"name\": \"{0}-final\", \"executorMemory\": \"4G\", \"executorCores\": 4, \"numExecutors\": 10, \"driverMemory\": \"4G\"}}\"\"\".format(username)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88c577c2-3ed9-4d4d-8bba-c270a5a27420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>9313</td><td>application_1652960972356_5123</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster029.iccluster.epfl.ch:8088/proxy/application_1652960972356_5123/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster052.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1652960972356_5123_01_000001/eric\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic(\n",
    "    \"spark\", \"add -s {0}-final -l python -u {1} -k\".format(username, server)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639289ef-7387-4989-891d-39d442e20679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "import pyspark.sql.functions as functions\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "delayTimeMax = 90\n",
    "N = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdffeefe-ab8c-4dc6-90f1-d96ce099e1ff",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## stops and sbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e8e82e-c5c0-49fe-88ce-1cb1cdf28966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "stops = spark.read.option(\"header\",True).csv('/user/sixu/work/stops_main.csv')\n",
    "stops = stops.drop(\"_c0\")\n",
    "stops = stops.withColumnRenamed(\"main_id\", \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5fb49b-e4df-4a1c-ad8d-eb05709f2fc7",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f646cae9-6cf9-44a4-92eb-21071e3e08e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# Calculate cases of trip on time\n",
    "def is_arrive_on_time(arr_sch, arr_act):\n",
    "    if arr_sch != '' and arr_act != '':\n",
    "        #compare the difference of them\n",
    "        arr_date1 = parse(arr_sch)\n",
    "        arr_date2 = parse(arr_act)\n",
    "        res_arr = (arr_date1 - arr_date2).total_seconds()\n",
    "        if res_arr < -delayTimeMax :\n",
    "            return 0\n",
    "    return 1\n",
    "is_arrive_on_time_udf = functions.udf(is_arrive_on_time,IntegerType())\n",
    "\n",
    "# Retrive the data based on corrsponding trip_id\n",
    "def getDataOnDTrip(tripId):\n",
    "    # filter trip\n",
    "    sbb_trip = sbb.filter(sbb.trip_id == tripId)\n",
    "    \n",
    "    # join and get stop_id\n",
    "    sbb_trip = sbb_trip.join(stops, sbb_trip.stop_name2==stops.stop_name, \"inner\")\n",
    "    sbb_trip = sbb_trip.drop(\"stop_name2\")\n",
    "    sbb_trip = sbb_trip.withColumnRenamed(\"main_id\", \"stop_id\")\n",
    "    \n",
    "    return sbb_trip\n",
    "\n",
    "# Retrive all data\n",
    "def getAllData():\n",
    "    # read data\n",
    "    sbb = spark.read.orc('/data/sbb/orc/istdaten')\n",
    "    # filter by date and not additional trip\n",
    "    sbb = sbb.filter(sbb.zusatzfahrt_tf=='false')\n",
    "    # keep stops in 15km radius\n",
    "    sbb = sbb.join(stops, sbb.haltestellen_name==stops.stop_name, \"inner\")\n",
    "    \n",
    "    # select necessary columns\n",
    "    sbb = sbb.select(\"haltestellen_name\", \"fahrt_bezeichner\",\"faellt_aus_tf\",\"ankunftszeit\",\"an_prognose\",\"abfahrtszeit\",\"ab_prognose\",\"durchfahrt_tf\")\n",
    "    # rename\n",
    "    newColumns = [\"stop_name2\",\"trip_id\",\"failed\",\"arrival_schedule\",\"arrival_actual\",\"departure_schedule\",\"departure_actual\",\"not_stop\"]\n",
    "    sbb = sbb.toDF(*newColumns)\n",
    "    \n",
    "    # join and get stop_id\n",
    "    sbb = sbb.join(stops, sbb.stop_name2==stops.stop_name, \"inner\")\n",
    "    sbb = sbb.drop(\"stop_name2\")\n",
    "    sbb = sbb.withColumnRenamed(\"main_id\", \"stop_id\")\n",
    "    return sbb\n",
    "\n",
    "# Retrive the data based on corrsponding date\n",
    "def getDataOnDate(date):\n",
    "    # read data\n",
    "    sbb = spark.read.orc('/data/sbb/orc/istdaten')\n",
    "    # filter by date and not additional trip\n",
    "    sbb = sbb.filter(sbb.betriebstag==date).filter(sbb.zusatzfahrt_tf=='false')\n",
    "    # keep stops in 15km radius\n",
    "    sbb = sbb.join(stops, sbb.haltestellen_name==stops.stop_name, \"inner\")\n",
    "    \n",
    "    # select necessary columns\n",
    "    sbb = sbb.select(\"haltestellen_name\", \"fahrt_bezeichner\",\"faellt_aus_tf\",\"ankunftszeit\",\"an_prognose\",\"abfahrtszeit\",\"ab_prognose\",\"durchfahrt_tf\")\n",
    "    # rename\n",
    "    newColumns = [\"stop_name2\",\"trip_id\",\"failed\",\"arrival_schedule\",\"arrival_actual\",\"departure_schedule\",\"departure_actual\",\"not_stop\"]\n",
    "    sbb = sbb.toDF(*newColumns)\n",
    "    \n",
    "    # join and get stop_id\n",
    "    sbb = sbb.join(stops, sbb.stop_name2==stops.stop_name, \"inner\")\n",
    "    sbb = sbb.drop(\"stop_name2\")\n",
    "    sbb = sbb.withColumnRenamed(\"main_id\", \"stop_id\")\n",
    "    return sbb\n",
    "\n",
    "# def getConfidenceByTripId(tripID):\n",
    "#     sbb_trip =  getDataOnDTrip(tripID)\n",
    "#     if(sbb_trip.count() == 0): return None\n",
    "#     sbb_trip = sbb_trip.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_trip.arrival_schedule, sbb_trip.arrival_actual))\n",
    "#     Trips_confidence = sbb_trip.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"}).first()\n",
    "#     return Trips_confidence['avg(is_arrive_on_time)']\n",
    "\n",
    "# Get the confidence by trip_id\n",
    "def getConfidenceByTripId(df, tripID):\n",
    "    return df.filter(df.trip_id == tripID).first().Confidence\n",
    "getConfidenceByTripId_udf = functions.udf(getConfidenceByTripId,FloatType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190528b-0883-4f73-9c2a-288628e37e06",
   "metadata": {},
   "source": [
    "## Create confidence data based on date ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4485714-414a-4748-9666-e3e592ca583e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark\n",
    "sbb_all = getAllData()\n",
    "trip_id_list = getDataOnDate('13.05.2019').select(\"trip_id\").distinct().withColumnRenamed(\"trip_id\", \"trip_id2\")\n",
    "sbb_date = sbb_all.join(trip_id_list, trip_id_list.trip_id2 == sbb_all.trip_id, \"inner\").drop(\"trip_id2\")\n",
    "\n",
    "sbb_date = sbb_date.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_date.arrival_schedule, sbb_date.arrival_actual))\n",
    "Trips_confidence = sbb_date.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"})\\\n",
    "                            .withColumnRenamed(\"avg(is_arrive_on_time)\", \"Confidence\")\n",
    "\n",
    "# Write the results to the work directory\n",
    "Trips_confidence.write.option(\"header\",True).csv(\"/user/ymao/work/confidence_13_05_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "350f3245-0844-4223-a0ac-0ac60d5ae7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "sbb_all = getAllData()\n",
    "trip_id_list = getDataOnDate('14.05.2019').select(\"trip_id\").distinct().withColumnRenamed(\"trip_id\", \"trip_id2\")\n",
    "sbb_date = sbb_all.join(trip_id_list, trip_id_list.trip_id2 == sbb_all.trip_id, \"inner\").drop(\"trip_id2\")\n",
    "\n",
    "sbb_date = sbb_date.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_date.arrival_schedule, sbb_date.arrival_actual))\n",
    "Trips_confidence = sbb_date.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"})\\\n",
    "                            .withColumnRenamed(\"avg(is_arrive_on_time)\", \"Confidence\")\n",
    "\n",
    "# Write the results to the work directory\n",
    "Trips_confidence.write.option(\"header\",True).csv(\"/user/ymao/work/confidence_14_05_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "044416fb-3b4a-47d8-ab8e-37e71d20f1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "sbb_all = getAllData()\n",
    "trip_id_list = getDataOnDate('15.05.2019').select(\"trip_id\").distinct().withColumnRenamed(\"trip_id\", \"trip_id2\")\n",
    "sbb_date = sbb_all.join(trip_id_list, trip_id_list.trip_id2 == sbb_all.trip_id, \"inner\").drop(\"trip_id2\")\n",
    "\n",
    "sbb_date = sbb_date.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_date.arrival_schedule, sbb_date.arrival_actual))\n",
    "Trips_confidence = sbb_date.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"})\\\n",
    "                            .withColumnRenamed(\"avg(is_arrive_on_time)\", \"Confidence\")\n",
    "\n",
    "# Write the results to the work directory\n",
    "Trips_confidence.write.option(\"header\",True).csv(\"/user/ymao/work/confidence_15_05_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da0d939f-c6dd-41a0-87a1-590ac577965e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "sbb_all = getAllData()\n",
    "trip_id_list = getDataOnDate('16.05.2019').select(\"trip_id\").distinct().withColumnRenamed(\"trip_id\", \"trip_id2\")\n",
    "sbb_date = sbb_all.join(trip_id_list, trip_id_list.trip_id2 == sbb_all.trip_id, \"inner\").drop(\"trip_id2\")\n",
    "\n",
    "sbb_date = sbb_date.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_date.arrival_schedule, sbb_date.arrival_actual))\n",
    "Trips_confidence = sbb_date.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"})\\\n",
    "                            .withColumnRenamed(\"avg(is_arrive_on_time)\", \"Confidence\")\n",
    "\n",
    "# Write the results to the work directory\n",
    "Trips_confidence.write.option(\"header\",True).csv(\"/user/ymao/work/confidence_16_05_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8714f197-65a7-4ddf-8789-a0a80063acd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "sbb_all = getAllData()\n",
    "trip_id_list = getDataOnDate('17.05.2019').select(\"trip_id\").distinct().withColumnRenamed(\"trip_id\", \"trip_id2\")\n",
    "sbb_date = sbb_all.join(trip_id_list, trip_id_list.trip_id2 == sbb_all.trip_id, \"inner\").drop(\"trip_id2\")\n",
    "\n",
    "sbb_date = sbb_date.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_date.arrival_schedule, sbb_date.arrival_actual))\n",
    "Trips_confidence = sbb_date.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"})\\\n",
    "                            .withColumnRenamed(\"avg(is_arrive_on_time)\", \"Confidence\")\n",
    "\n",
    "# Write the results to the work directory\n",
    "Trips_confidence.write.option(\"header\",True).csv(\"/user/ymao/work/confidence_17_05_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ae9c9c0-699a-422f-882a-f72680cbf336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Invalid status code '404' from http://iccluster029.iccluster.epfl.ch:8998/sessions/8803 with error payload: \"Session '8803' not found.\"\n"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "con_13 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_13_05_2019.csv')\n",
    "con_14 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_14_05_2019.csv')\n",
    "con_15 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_15_05_2019.csv')\n",
    "con_16 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_16_05_2019.csv')\n",
    "con_17 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_17_05_2019.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484271a5-901f-4e85-bd73-edc1187455c3",
   "metadata": {},
   "source": [
    "### Filter data with threshold ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db623f4-f352-4afd-ac4a-6c7353ce5717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: string (nullable = true)\n",
      " |-- failed: string (nullable = true)\n",
      " |-- arrival_schedule: string (nullable = true)\n",
      " |-- arrival_actual: string (nullable = true)\n",
      " |-- departure_schedule: string (nullable = true)\n",
      " |-- departure_actual: string (nullable = true)\n",
      " |-- not_stop: string (nullable = true)\n",
      " |-- stop_name: string (nullable = true)\n",
      " |-- stop_lat: string (nullable = true)\n",
      " |-- stop_lon: string (nullable = true)\n",
      " |-- stop_id: string (nullable = true)\n",
      "\n",
      "317526"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "threshold = 0.7\n",
    "stop_513 = spark.read.option(\"header\",True).csv('/user/sixu/work/actual_data_513.csv')\n",
    "con_13 = spark.read.option(\"header\",True).csv('/user/ymao/work/confidence_13_05_2019.csv')\n",
    "con_13 = con_13.filter(con_13.Confidence > threshold).withColumnRenamed('trip_id', 'trip_id_over_threshold')\n",
    "stop_513_filttered = stop_513.join(con_13, stop_513.trip_id == con_13.trip_id_over_threshold, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b7390e3-c85f-43bc-b778-665d5ff2638e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "stop_513_filttered.write.option(\"header\",True).csv(\"/user/ymao/work/actual_data_513_filtered_0.7.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
