{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a55da37e-38c4-403f-bdcd-064cf4f66b38",
   "metadata": {},
   "source": [
    "# Set up spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13450e66-3566-485c-a5e2-56f42059ecf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sparkmagic.magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e957436b-b9f9-484f-b3f2-5f23233f0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython import get_ipython\n",
    "\n",
    "# set the application name as \"<your_gaspar_id>-homework3\"\n",
    "username = os.environ['RENKU_USERNAME']\n",
    "server = \"http://iccluster029.iccluster.epfl.ch:8998\"\n",
    "\n",
    "get_ipython().run_cell_magic(\n",
    "    'spark',\n",
    "    line='config', \n",
    "    cell=\"\"\"{{ \"name\": \"{0}-final\", \"executorMemory\": \"4G\", \"executorCores\": 4, \"numExecutors\": 10, \"driverMemory\": \"4G\"}}\"\"\".format(username)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a60336a7-04d1-4631-9594-00949f35d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>9059</td><td>application_1652960972356_4842</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster029.iccluster.epfl.ch:8088/proxy/application_1652960972356_4842/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster052.iccluster.epfl.ch:8042/node/containerlogs/container_e05_1652960972356_4842_01_000001/eric\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "get_ipython().run_line_magic(\n",
    "    \"spark\", \"add -s {0}-final -l python -u {1} -k\".format(username, server)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6fbb3ae-3264-4fdb-9d61-31706fa5aefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "import pyspark.sql.functions as functions\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "delayTimeMax = 60\n",
    "N = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f1b873a-3a23-40f5-ab64-1232da49bcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "token = \"pk.eyJ1IjoiY29jb251dG51dCIsImEiOiJjbDNscTZhbHowMmxtM2pwajl3Yjd1ejF0In0.PXbwkPmWYXrAhQsus3ypVA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66922fb6-4033-4a69-b44b-ffde810c883b",
   "metadata": {},
   "source": [
    "# Load data\n",
    "## Stops\n",
    "- stop_name\n",
    "- stop_lat\n",
    "- stop_lon\n",
    "- stop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a8d8c463-0524-4c6d-96fc-d82133a1be2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "stops = spark.read.option(\"header\",True).csv('/user/sixu/work/stops_main.csv')\n",
    "stops = stops.drop(\"_c0\")\n",
    "stops = stops.withColumnRenamed(\"main_id\", \"stop_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c840e0ed-2633-42f8-bf10-3644144a92f0",
   "metadata": {},
   "source": [
    "## Daily actual data\n",
    "- trip_id `FAHRT_BEZEICHNER`: identifies the trip\n",
    "- failed `FAELLT_AUS_TF`: boolean, true if this trip failed (cancelled or not completed)\n",
    "- arrival_schedule `ANKUNFTSZEIT`: arrival time at the stop according to schedule\n",
    "- arrival_actual `AN_PROGNOSE`: actual arrival time\n",
    "- departure_schedule `ABFAHRTSZEIT`: departure time at the stop according to schedule\n",
    "- departure_actual `AB_PROGNOSE`: actual departure time\n",
    "- not_stop `DURCHFAHRT_TF`: boolean, true if the transport does not stop there\n",
    "- stop_name `HALTESTELLEN_NAME`: name of the stop\n",
    "- stop_lat\n",
    "- stop_lon\n",
    "- stop_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "52fdb108-ed07-4e78-b0a5-ffbc27907535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "actual_data_513 = spark.read.option(\"header\",True).csv('/user/ymao/work/actual_data_513_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f6274-841b-4f8a-8616-85b7c8e0dce8",
   "metadata": {},
   "source": [
    "## Walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f7cb9197-0f91-446e-a605-fa8be71b1d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "## Stops infomation\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "Stops_info = spark.read.option(\"header\",True).csv('/user/sixu/work/stops_main.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860315a-163b-4a6a-8bb9-cf781d696605",
   "metadata": {},
   "source": [
    "# Confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "bce5223f-4f25-4bc8-8630-31f1a80b5776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "# Calculate cases of trip on time\n",
    "def is_arrive_on_time(arr_sch, arr_act):\n",
    "    if arr_sch != '' and arr_act != '':\n",
    "        #compare the difference of them\n",
    "        arr_date1 = parse(arr_sch)\n",
    "        arr_date2 = parse(arr_act)\n",
    "        res_arr = (arr_date1 - arr_date2).total_seconds()\n",
    "        if res_arr < -delayTimeMax :\n",
    "            return 0\n",
    "    return 1\n",
    "is_arrive_on_time_udf = functions.udf(is_arrive_on_time,IntegerType())\n",
    "\n",
    "def getDataOnDTrip(tripId):\n",
    "    # filter trip\n",
    "    sbb_trip = sbb.filter(sbb.trip_id == tripId)\n",
    "    \n",
    "    # join and get stop_id\n",
    "    sbb_trip = sbb_trip.join(stops, sbb_trip.stop_name2==stops.stop_name, \"inner\")\n",
    "    sbb_trip = sbb_trip.drop(\"stop_name2\")\n",
    "    sbb_trip = sbb_trip.withColumnRenamed(\"main_id\", \"stop_id\")\n",
    "    \n",
    "    return sbb_trip\n",
    "\n",
    "# implemented function\n",
    "def getConfidenceByTripId(tripID):\n",
    "    sbb_trip =  getDataOnDTrip(tripID)\n",
    "    if(sbb_trip.count() == 0): return None\n",
    "    sbb_trip = sbb_trip.withColumn(\"is_arrive_on_time\", is_arrive_on_time_udf(sbb_trip.arrival_schedule, sbb_trip.arrival_actual))\n",
    "    Trips_confidence = sbb_trip.groupBy(\"trip_id\").agg({\"is_arrive_on_time\": \"avg\"}).first()\n",
    "    return Trips_confidence['avg(is_arrive_on_time)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b8550c99-d8cd-4345-86a3-05f07d3544b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dfs = Stops_info.alias(\"s1\").crossJoin(Stops_info.alias(\"s2\"))\\\n",
    "        .select(col(\"s1.main_id\").alias(\"s1_stop_id\"), col(\"s1.stop_name\").alias(\"s1_stop_name\"),\n",
    "                col(\"s1.stop_lat\").alias(\"s1_stop_lat\"), col(\"s1.stop_lon\").alias(\"s1_stop_lon\"),\n",
    "                col(\"s2.main_id\").alias(\"s2_stop_id\"), col(\"s2.stop_name\").alias(\"s2_stop_name\"),\n",
    "                col(\"s2.stop_lat\").alias(\"s2_stop_lat\"), col(\"s2.stop_lon\").alias(\"s2_stop_lon\"),)\\\n",
    "        .filter('s1.main_id != s2.main_id')\n",
    "\n",
    "dfs=dfs.withColumn('s1_stop_lat',dfs['s1_stop_lat'].cast(\"float\"))\n",
    "dfs=dfs.withColumn('s1_stop_lon',dfs['s1_stop_lon'].cast(\"float\"))\n",
    "dfs=dfs.withColumn('s2_stop_lat',dfs['s2_stop_lat'].cast(\"float\"))\n",
    "dfs=dfs.withColumn('s2_stop_lon',dfs['s2_stop_lon'].cast(\"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fa736e50-43fb-4f06-904e-29ec9b2f8da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.sql.types import *\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "\n",
    "def geodesic(lon1, lat1, lon2, lat2):\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371\n",
    "    return c * r * 1000\n",
    "\n",
    "geodesic_udf = functions.udf(geodesic,FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "39063637-57a9-44bb-833b-f8f155ca012d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "dfs = dfs.withColumn('distance', geodesic_udf(dfs.s1_stop_lon, dfs.s1_stop_lat, dfs.s2_stop_lon, dfs.s2_stop_lat))\n",
    "dfs = dfs.filter(dfs.distance < 500)\n",
    "stops_walkable = dfs.select(col(\"s1_stop_id\"), col(\"s2_stop_id\"), col(\"distance\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b56db-0428-4f40-ad00-6294550fbad3",
   "metadata": {},
   "source": [
    "# Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "77e8d0ae-7755-49c5-99c5-59b8cf414189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "withinHour = 1\n",
    "\n",
    "def caculate_time(h, time_string):\n",
    "    pre_part = time_string[0 : 11]\n",
    "    time_part = time_string[11 : ]\n",
    "    \n",
    "    time_rest = time_part[2:]\n",
    "    t = int(time_part[0:2])-h\n",
    "    time_res = str(t) + time_rest\n",
    "    if t < 10 :\n",
    "        time_res = '0' + time_res\n",
    "    return pre_part + time_res\n",
    "\n",
    "def direct_routes_withinHour(df, stop_id1, stop_id2, arrival_time, use_stop_id=False):\n",
    "    '''\n",
    "    Start from stop_id1\n",
    "    End to stop_id2 before arrival_time\n",
    "    '''\n",
    "    if use_stop_id:\n",
    "        ## 不同时间的同一路经trip id 不一样！\n",
    "        # 所有过stop_id1的trips, 出发时间 < 规定到达时间\n",
    "        trips_id1_df = df.filter((df['stop_id'] == stop_id1) & (df[\"departure_schedule\"] < arrival_time)).select(\"trip_id\", \"arrival_schedule\", \"departure_schedule\", \"stop_id\" ).distinct()\n",
    "        #     trips_id1_df.orderBy(\"departure_time\",ascending=False).show(15)\n",
    "        # arrival_time 之前过stop_id2 的trips\n",
    "        trips_id2_df = df.filter((df['stop_id'] == stop_id2) & (df[\"arrival_schedule\"] < arrival_time) & (df[\"arrival_schedule\"] > caculate_time(withinHour, arrival_time))).select(\"trip_id\", \"arrival_schedule\",\"departure_schedule\", \"stop_id\").distinct()\n",
    "        trips_id2_df = trips_id2_df.withColumnRenamed(\"stop_id\",\"stop_id2\")\n",
    "    else:\n",
    "        trips_id1_df = df.filter((df['stop_id'] == stop_id1) & (df[\"departure_schedule\"] < arrival_time)).select(\"trip_id\", \"arrival_schedule\", \"departure_schedule\").distinct()\n",
    "        trips_id2_df = df.filter((df['stop_id'] == stop_id2) & (df[\"arrival_schedule\"] < arrival_time) & (df[\"arrival_schedule\"] > caculate_time(withinHour, arrival_time))).select(\"trip_id\", \"arrival_schedule\", \"departure_schedule\").distinct()\n",
    "    \n",
    "    trips_id2_df = trips_id2_df.withColumnRenamed(\"trip_id\",\"trip_id2\")\n",
    "    trips_id2_df = trips_id2_df.withColumnRenamed(\"departure_schedule\",\"departure_schedule2\")\n",
    "    trips_id2_df = trips_id2_df.withColumnRenamed(\"arrival_schedule\",\"arrival_schedule2\")\n",
    "    \n",
    "\n",
    "    direct_trips = trips_id1_df.join(trips_id2_df, trips_id1_df[\"trip_id\"] == trips_id2_df[\"trip_id2\"], \"inner\")\n",
    "    # drop duplicate trip_id\n",
    "    direct_trips = direct_trips.drop(\"trip_id2\")\n",
    "    \n",
    "    # 把反向的删除了\n",
    "    direct_trips = direct_trips.filter(direct_trips[\"departure_schedule\"] < direct_trips[\"arrival_schedule2\"])\n",
    "#     direct_trips.orderBy(\"arrival_schedule\", ascending=False).show(100, False)\n",
    "    direct_trips = direct_trips.orderBy(\"arrival_schedule2\", ascending=False)\n",
    "    return direct_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ac4b3ce6-9889-4365-9930-9d7e47bfe905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "def filter_data_between(selected_data, tid, sid1, sid2):\n",
    "#     trip_data = selected_data.filter(selected_data.trip_id == tid)\n",
    "#     start_time = trip_data.filter(trip_data[\"stop_id\"] == sid1).first().departure_schedule\n",
    "#     end_time = trip_data.filter(trip_data[\"stop_id\"] == sid2).first().arrival_schedule\n",
    "#     trip_data = trip_data.filter(trip_data[\"departure_schedule\"] >= start_time).filter(trip_data[\"arrival_schedule\"] <= end_time)\n",
    "#     return trip_data\n",
    "    trip_data = selected_data.filter(selected_data.trip_id == tid)\n",
    "    trip_data = trip_data.orderBy(\"arrival_schedule\", \"departure_schedule\").withColumn(\"id\",monotonically_increasing_id())\n",
    "    start_id = trip_data.filter(trip_data[\"stop_id\"] == sid1).first().id\n",
    "    end_id = trip_data.filter(trip_data[\"stop_id\"] == sid2).first().id\n",
    "    trip_data = trip_data.filter(trip_data[\"id\"] >= start_id).filter(trip_data[\"id\"] <= end_id)\n",
    "    trip_data = trip_data.drop(\"id\")\n",
    "    return trip_data\n",
    "\n",
    "def get_schedule_from_direct_routes(data, trip_ids, stop_id1, stop_id2):\n",
    "    trip_ids_list = trip_ids.select(\"trip_id\").rdd.flatMap(lambda x: x).collect()\n",
    "    # all valid trips\n",
    "    selected_data = data.filter(data.trip_id.isin(trip_ids_list))\\\n",
    "                    .select(\"trip_id\",\"stop_name\",\"arrival_schedule\",\"departure_schedule\",\"stop_id\",\"stop_lat\",\"stop_lon\")\\\n",
    "                    .orderBy(\"trip_id\", \"arrival_schedule\")\n",
    "    \n",
    "    # empty dataframe to put result\n",
    "    schema = StructType([\n",
    "        StructField(\"trip_id\",StringType(),True),\n",
    "        StructField(\"stop_name\",StringType(),True),\n",
    "        StructField(\"arrival_schedule\",StringType(),True),\n",
    "        StructField(\"departure_schedule\",StringType(),True),\n",
    "        StructField(\"stop_id\",StringType(),True),\n",
    "        StructField(\"stop_lat\",StringType(),True),\n",
    "        StructField(\"stop_lon\",StringType(),True),\n",
    "        StructField(\"color\",StringType(),True),\n",
    "        StructField(\"schedule_id\",StringType(),True)\n",
    "    ])\n",
    "    result_schedule = spark.createDataFrame([], schema)\n",
    "    \n",
    "    # for each group, keep stops between stop_id1 and stop_id2, calculate confidence\n",
    "    cnt = 1\n",
    "    for i in trip_ids_list:\n",
    "        trip_data = filter_data_between(selected_data, i, stop_id1, stop_id2)\n",
    "        # add distinct schedule_id\n",
    "        schedule_id = \"d_\" + str(cnt)\n",
    "        trip_data = trip_data.withColumn(\"color\", lit('rgb(255, 0, 0)'))\n",
    "        trip_data = trip_data.withColumn(\"schedule_id\", lit(schedule_id))\n",
    "        result_schedule = result_schedule.union(trip_data)\n",
    "        cnt += 1\n",
    "    \n",
    "    return result_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def7fce9-c8f2-475c-acbf-85a8e44ec30f",
   "metadata": {},
   "source": [
    "# One transit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8488f959-2716-4c44-bd47-a2f00e9e3b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "from pyspark.sql.functions import col\n",
    "# def one_transit_helper(i):\n",
    "#     print(i)\n",
    "#     subpath1 = direct_routes(df, stop_id1, i, arrival_time).select(\"trip_id\").distinct()\n",
    "#     print(\"find subpath1!\")\n",
    "#     subpath1.show(False)\n",
    "#     subpath2 = direct_routes(df, i, stop_id2, arrival_time).select(\"trip_id\").distinct()\n",
    "#     print(\"find subpath2!\")\n",
    "#     subpath2.show(False)\n",
    "    \n",
    "\n",
    "def one_transit(df, stop_id1, stop_id2, arrival_time):\n",
    "    #找到所有满足条件的trip1的id和arrive_time\n",
    "    trips_id1_df = df.filter((df['stop_id'] == stop_id1) & (df[\"departure_schedule\"] < arrival_time)).select(\"trip_id\", \"arrival_schedule\").distinct()\n",
    "    #找出所有直达的trip2的id\n",
    "    direct_trip_id = direct_routes_withinHour(df, stop_id1, stop_id2, arrival_time).select(\"trip_id\").distinct()\n",
    "    #trip1去除所有直达的trip1的id\n",
    "    selected_trip_id = trips_id1_df.select(\"trip_id\").subtract(direct_trip_id.select(\"trip_id\")).distinct()\n",
    "    #非直达的id转成list方便后面isin运算\n",
    "    selected_list = selected_trip_id.rdd.flatMap(lambda x: x).collect()\n",
    "    #找出非直达id的df的内容\n",
    "    trips_id2 = df.filter(col(\"trip_id\").isin(selected_list))\n",
    "\n",
    "    stops_in_trip_id2 = trips_id2.select(\"stop_id\").distinct()\n",
    "#     stops_in_trip_id2.show()\n",
    "    \n",
    "\n",
    "    for i in stops_in_trip_id2:\n",
    "        #找到每一个站名，然后分别计算两边，记住i是unicode，如果有错误，可以尝试转换成str(i)\n",
    "        subpath1 = direct_routes_withinHour(df, stop_id1, i, arrival_time, True).select(\"*\").distinct()\n",
    "#         print(\"find subpath1!\")\n",
    "#         subpath1.orderBy(\"arrival_schedule2\", ascending=False).show(100 ,False)\n",
    "        subpath2 = direct_routes_withinHour(df, i, stop_id2, arrival_time, True).select(\"*\").distinct()\n",
    "#         print(\"find subpath2!\")\n",
    "#         subpath2.show(100, False)\n",
    "\n",
    "    subpath2 = subpath2.withColumnRenamed(\"trip_id\",\"trip_id_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"arrival_schedule\",\"arrival_schedule_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"departure_schedule\",\"departure_schedule_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"stop_id\",\"stop_id_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"arrival_schedule2\",\"arrival_schedule2_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"departure_schedule2\",\"departure_schedule2_2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"stop_id2\",\"stop_id2_2\")\n",
    "\n",
    "    subpath_join = subpath1.crossJoin(subpath2)\n",
    "    # subpath1 的到达站 = 中转站 = subpath2 的起始站\n",
    "    \n",
    "    subpath_no_walk = subpath_join.filter((subpath_join[\"stop_id2\"] == subpath_join[\"stop_id_2\"]) & (subpath_join[\"departure_schedule2\"] <= subpath_join[\"arrival_schedule_2\"]) & (subpath_join[\"trip_id\"] != subpath_join[\"trip_id_2\"]))\n",
    "    ## Here for adding walkable stops!!!\n",
    "    subpath_join_filter = subpath_join.filter((subpath_join[\"departure_schedule2\"] <= subpath_join[\"arrival_schedule_2\"]) & (subpath_join[\"trip_id\"] != subpath_join[\"trip_id_2\"]))\n",
    "    condition = (stops_walkable.s1_stop_id == subpath_join_filter.stop_id2) & (stops_walkable.s2_stop_id == subpath_join_filter.stop_id_2)\n",
    "    subpath_join_filter = subpath_join_filter.join(stops_walkable, condition, \"inner\").drop(\"s1_stop_id\", \"s2_stop_id\", \"distance\")\n",
    "\n",
    "    subpath_join_filter = subpath_join_filter.union(subpath_no_walk)\n",
    "\n",
    "    path_one_transit = subpath_join_filter.select(\"trip_id\", \"stop_id\", \"departure_schedule\", \"stop_id2\", \"trip_id_2\", \"arrival_schedule2_2\")\n",
    "    path_one_transit = path_one_transit.orderBy(\"departure_schedule\", ascending=False)\n",
    "    \n",
    "    return path_one_transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8ab0a622-8810-43ea-ba7a-7c32ca006366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "\n",
    "def get_schedule_from_one_transit(data, path_one_transit, stop_id1, stop_id2):\n",
    "    trip_ids_list_1 = path_one_transit.select(\"trip_id\").rdd.flatMap(lambda x: x).collect()\n",
    "    trip_ids_list_2 = path_one_transit.select(\"trip_id_2\").rdd.flatMap(lambda x: x).collect()\n",
    "    trip_ids_list = trip_ids_list_1 + trip_ids_list_2\n",
    "    \n",
    "    # all valid trips\n",
    "    selected_data = data.filter(data.trip_id.isin(trip_ids_list))\\\n",
    "                    .select(\"trip_id\",\"stop_name\",\"arrival_schedule\",\"departure_schedule\",\"stop_id\",\"stop_lat\",\"stop_lon\")\\\n",
    "                    .orderBy(\"trip_id\", \"arrival_schedule\")\n",
    "    \n",
    "    # empty dataframe to put result\n",
    "    schema = StructType([\n",
    "        StructField(\"trip_id\",StringType(),True),\n",
    "        StructField(\"stop_name\",StringType(),True),\n",
    "        StructField(\"arrival_schedule\",StringType(),True),\n",
    "        StructField(\"departure_schedule\",StringType(),True),\n",
    "        StructField(\"stop_id\",StringType(),True),\n",
    "        StructField(\"stop_lat\",StringType(),True),\n",
    "        StructField(\"stop_lon\",StringType(),True),\n",
    "        StructField(\"color\",StringType(),True),\n",
    "        StructField(\"schedule_id\",StringType(),True)\n",
    "    ])\n",
    "    result_schedule = spark.createDataFrame([], schema)\n",
    "    \n",
    "    # for each group, keep stops between stop_id1 and stop_id2, calculate confidence\n",
    "    cnt = 1\n",
    "    for i in path_one_transit.collect():\n",
    "        trip_id1 = i[\"trip_id\"]\n",
    "        trip_id2 = i[\"trip_id_2\"]\n",
    "        transit_stop = i[\"stop_id2\"]\n",
    "        \n",
    "        # filter first half\n",
    "        trip_data1 = filter_data_between(selected_data, trip_id1, stop_id1, transit_stop)\n",
    "        # filter second half\n",
    "        trip_data2 = filter_data_between(selected_data, trip_id2, transit_stop, stop_id2)\n",
    "        \n",
    "        # add distinct schedule_id\n",
    "        schedule_id = \"t1_\" + str(cnt)\n",
    "        trip_data1 = trip_data1.withColumn(\"color\", lit('rgb(255, 0, 0)'))\n",
    "        trip_data2 = trip_data2.withColumn(\"color\", lit('rgb(0, 255, 0)'))\n",
    "        trip_data = trip_data1.union(trip_data2)\n",
    "        trip_data = trip_data.withColumn(\"schedule_id\", lit(schedule_id))\n",
    "        result_schedule = result_schedule.union(trip_data)\n",
    "        cnt += 1\n",
    "    \n",
    "    return result_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ebd377-e028-4e3b-8220-2ad7d0e7e656",
   "metadata": {},
   "source": [
    "# Two transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9e867ce4-94d1-4fde-a678-eee98385005b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "def two_transit(df, stop_id1, stop_id2, arrival_time):\n",
    "    #找到所有满足条件的trip1的id和arrive_time\n",
    "    trips_id1_df = df.filter((df['stop_id'] == stop_id1) & (df[\"departure_schedule\"] < arrival_time)).select(\"trip_id\", \"arrival_schedule\").distinct()\n",
    "    \n",
    "    #找出所有直达的trip2的id\n",
    "    direct_trip_id = direct_routes_withinHour(df, stop_id1, stop_id2, arrival_time).select(\"trip_id\").distinct()\n",
    "    #trip1去除所有直达的trip1的id\n",
    "    selected_trip_id = trips_id1_df.select(\"trip_id\").subtract(direct_trip_id.select(\"trip_id\")).distinct()\n",
    "    \n",
    "    #找到所有一次中转能到的trip1的id\n",
    "    one_transit_id = one_transit(df, stop_id1, stop_id2, arrival_time).select(\"trip_id\").distinct()\n",
    "    #trip1去除所有直达或一次中转的trip1的id\n",
    "    selected_trip_id = selected_trip_id.select(\"trip_id\").subtract(one_transit_id.select(\"trip_id\")).distinct()\n",
    "    \n",
    "    #非直达的id转成list方便后面isin运算\n",
    "    selected_list = selected_trip_id.rdd.flatMap(lambda x: x).collect()\n",
    "    #找出非直达 非一次中转 id的df的内容\n",
    "    trips_id2 = df.filter(col(\"trip_id\").isin(selected_list))\n",
    "\n",
    "    stops_in_trip_id2 = trips_id2.select(\"stop_id\").distinct()\n",
    "    \n",
    "    # 然后到这些站后可以一次中转到达 stop_id2\n",
    "    for i in stops_in_trip_id2:\n",
    "        # 第一段trip\n",
    "#         print(\"path1\")\n",
    "        subpath1 = direct_routes_withinHour(df, stop_id1, i, arrival_time, True).distinct()\n",
    "#         subpath1.show()\n",
    "        # 从第一段trip的stop 经过一次中转到 stop_id2\n",
    "#         print(\"path2\")\n",
    "        subpath2 = one_transit(df, i, stop_id2, arrival_time)\n",
    "#         subpath2.show()\n",
    "       \n",
    "    subpath1 = subpath1.withColumnRenamed(\"stop_id2\",\"stop_id1\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"trip_id\",\"trip_id_1\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"arrival_schedule2_2\",\"arrival_schedule_3\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"stop_id2\",\"stop_id3\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"stop_id\",\"stop_id2\")\n",
    "    subpath2 = subpath2.withColumnRenamed(\"departure_schedule\",\"departure_schedule3\")\n",
    "        \n",
    "    subpath_join = subpath1.crossJoin(subpath2)\n",
    "    \n",
    "    subpath_join_filter = subpath_join.filter((subpath_join[\"stop_id1\"] == subpath_join[\"stop_id2\"]) & (subpath_join[\"arrival_schedule2\"] <= subpath_join[\"departure_schedule3\"]) & (subpath_join[\"stop_id3\"] != subpath_join[\"stop_id\"]))\n",
    "    subpath_join_filter = subpath_join_filter.filter((subpath_join_filter[\"trip_id\"] != subpath_join_filter[\"trip_id_1\"]) & (subpath_join_filter[\"trip_id\"] != subpath_join_filter[\"trip_id_2\"]) & (subpath_join_filter[\"trip_id_2\"] != subpath_join_filter[\"trip_id_1\"]))\n",
    "    path_two_transit = subpath_join_filter.select(\"trip_id\", \"departure_schedule\", \"arrival_schedule2\", \"stop_id1\", \"trip_id_1\", \"departure_schedule3\", \"stop_id3\", \"trip_id_2\", \"arrival_schedule_3\")\n",
    "    path_two_transit = path_two_transit.orderBy(\"departure_schedule\", ascending=False)\n",
    "\n",
    "    return path_two_transit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c177e329-b92a-4b4d-9f96-ced14949ff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "def get_schedule_from_two_transit(data, path_two_transit, stop_id1, stop_id2):\n",
    "    trip_ids_list_1 = path_two_transit.select(\"trip_id\").rdd.flatMap(lambda x: x).collect()\n",
    "    trip_ids_list_2 = path_two_transit.select(\"trip_id_1\").rdd.flatMap(lambda x: x).collect()\n",
    "    trip_ids_list_3 = path_two_transit.select(\"trip_id_2\").rdd.flatMap(lambda x: x).collect()\n",
    "    trip_ids_list = trip_ids_list_1 + trip_ids_list_2 + trip_ids_list_3\n",
    "    \n",
    "    # all valid trips\n",
    "    selected_data = data.filter(data.trip_id.isin(trip_ids_list))\\\n",
    "                    .select(\"trip_id\",\"stop_name\",\"arrival_schedule\",\"departure_schedule\",\"stop_id\",\"stop_lat\",\"stop_lon\")\\\n",
    "                    .orderBy(\"trip_id\", \"arrival_schedule\")\n",
    "    \n",
    "    # empty dataframe to put result\n",
    "    schema = StructType([\n",
    "        StructField(\"trip_id\",StringType(),True),\n",
    "        StructField(\"stop_name\",StringType(),True),\n",
    "        StructField(\"arrival_schedule\",StringType(),True),\n",
    "        StructField(\"departure_schedule\",StringType(),True),\n",
    "        StructField(\"stop_id\",StringType(),True),\n",
    "        StructField(\"stop_lat\",StringType(),True),\n",
    "        StructField(\"stop_lon\",StringType(),True),\n",
    "        StructField(\"color\",StringType(),True),\n",
    "        StructField(\"schedule_id\",StringType(),True)\n",
    "    ])\n",
    "    result_schedule = spark.createDataFrame([], schema)\n",
    "    \n",
    "    # for each group, keep stops between stop_id1 and stop_id2, calculate confidence\n",
    "    cnt = 1\n",
    "    for i in path_two_transit.collect():\n",
    "        trip_id1 = i[\"trip_id\"]\n",
    "        trip_id2 = i[\"trip_id_1\"]\n",
    "        trip_id3 = i[\"trip_id_2\"]\n",
    "        transit_stop1 = i[\"stop_id1\"]\n",
    "        transit_stop2 = i[\"stop_id3\"]\n",
    "        \n",
    "        # filter trip 1\n",
    "        trip_data1 = filter_data_between(selected_data, trip_id1, stop_id1, transit_stop1)\n",
    "        # filter trip 2\n",
    "        trip_data2 = filter_data_between(selected_data, trip_id2, transit_stop1, transit_stop2)\n",
    "        # filter trip 3\n",
    "        trip_data3 = filter_data_between(selected_data, trip_id3, transit_stop2, stop_id2)\n",
    "        \n",
    "        # add distinct schedule_id\n",
    "        schedule_id = \"t2_\" + str(cnt)\n",
    "        trip_data1 = trip_data1.withColumn(\"color\", lit('rgb(255, 0, 0)'))\n",
    "        trip_data2 = trip_data2.withColumn(\"color\", lit('rgb(0, 255, 0)'))\n",
    "        trip_data3 = trip_data3.withColumn(\"color\", lit('rgb(0, 0, 255)'))\n",
    "        trip_data = trip_data1.union(trip_data2).union(trip_data3)\n",
    "        trip_data = trip_data.withColumn(\"schedule_id\", lit(schedule_id))\n",
    "        result_schedule = result_schedule.union(trip_data)\n",
    "        cnt += 1\n",
    "    \n",
    "    return result_schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e989e4-253d-44e9-a724-2a8cb14cc67f",
   "metadata": {},
   "source": [
    "# Planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "23a30c75-435a-4ce8-8cc1-bbcf50eec092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark\n",
    "def top_time(df, nb):\n",
    "    df_order = df.orderBy(\"departure_schedule\", ascending=False)\n",
    "    df_order_list = df_order.select(\"departure_schedule\").rdd.flatMap(lambda x: x).collect()\n",
    "    if nb < len(df_order_list):\n",
    "        index = nb - 1\n",
    "    else:\n",
    "        index = len(df_order_list) - 1\n",
    "        \n",
    "    return df_order_list[index]\n",
    "\n",
    "def df_order(d1, d2, d3):\n",
    "    '''\n",
    "    d1 : direct routes\n",
    "    d2 : one transit\n",
    "    d3 : two transit\n",
    "    '''\n",
    "    d1d = d1.select(\"trip_id\", \"departure_schedule\")\n",
    "    d2d = d2.select(\"trip_id\", \"departure_schedule\")\n",
    "    d3d = d3.select(\"trip_id\", \"departure_schedule\")\n",
    "    df = d1d.union(d2d).union(d3d).orderBy(\"departure_schedule\", ascending=False)\n",
    "\n",
    "    time = top_time(df, 10)\n",
    "\n",
    "    d1_order = d1.filter(d1[\"departure_schedule\"] > time)\n",
    "    d2_order = d2.filter(d2[\"departure_schedule\"] > time)\n",
    "    d3_order = d3.filter(d3[\"departure_schedule\"] > time)\n",
    "    return d1_order, d2_order, d3_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "20da845c-35bf-4c91-9f31-cbd3ab5bfead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "5\n",
      "17"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "#  -o schedule\n",
    "df = actual_data_513\n",
    "start_id = \"8503006\"\n",
    "end_id = \"8503009\"\n",
    "arrival_time = \"13.05.2019 19:00:00\"\n",
    "\n",
    "# get trips\n",
    "direct_trips = direct_routes_withinHour(df, start_id, end_id, arrival_time)\n",
    "one_transit_trips = one_transit(df, start_id, end_id, arrival_time)\n",
    "two_transit_trips = two_transit(df, start_id, end_id, arrival_time)\n",
    "print(direct_trips.count())\n",
    "print(one_transit_trips.count())\n",
    "print(two_transit_trips.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0fc55061-fd3a-4494-b555-3fa6024e2546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n",
      "5"
     ]
    }
   ],
   "source": [
    "%%spark\n",
    "d1, d2, d3 = df_order(direct_trips, one_transit_trips, two_transit_trips)\n",
    "print(d1.count())\n",
    "print(d2.count())\n",
    "print(d3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8ab0d160-a6e8-4c0c-92d9-31562b3f2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%spark -o schedule\n",
    "schedule1 = get_schedule_from_direct_routes(df, d1, start_id, end_id)\n",
    "schedule2 = get_schedule_from_one_transit(df, d2, start_id, end_id)\n",
    "schedule3 = get_schedule_from_two_transit(df, d3, start_id, end_id)\n",
    "\n",
    "schedule = schedule1.union(schedule2).union(schedule3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0aaa0e-c7e0-4092-8cbe-295617d3b036",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7ec9b211-f9f6-495b-8fd4-ba19608f4535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550077109f5b4652873966994430b962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(options=('d_1', 't1_1', 't1_2', 't1_3', 't2_1', 't2_2', 't2_3', 't2_4', 't2_5'), value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prepare data\n",
    "schedule_list = schedule[\"schedule_id\"].unique().tolist()\n",
    "\n",
    "# figure\n",
    "layout = dict(hovermode='closest',\n",
    "    margin=dict(l=0, t=0, r=0, b=0, pad=0),\n",
    "    mapbox=dict(\n",
    "        accesstoken=token,\n",
    "        bearing=0,\n",
    "        center=go.layout.mapbox.Center(\n",
    "            lat=47.378177,\n",
    "            lon=8.540192\n",
    "        ),\n",
    "        pitch=0,\n",
    "        zoom=10\n",
    "    ))\n",
    "\n",
    "data = go.Scattermapbox(\n",
    "        lat=[],\n",
    "        lon=[],\n",
    "        mode='markers+lines',\n",
    "        marker=go.scattermapbox.Marker(size=5),\n",
    "        text=[]\n",
    "    )\n",
    "\n",
    "figure = go.FigureWidget(data=[data], layout=layout)\n",
    "table = widgets.Output()\n",
    "\n",
    "# update function\n",
    "def f(a):    \n",
    "    # select this schedule\n",
    "    df = schedule[schedule['schedule_id'] == choose_schedule.value].reset_index(drop=True)\n",
    "    df['arrival_schedule'] = df['arrival_schedule'].apply(lambda x: str(x).split()[1] if str(x)!=\"NaT\" else str(x))\n",
    "    df['departure_schedule'] = df['departure_schedule'].apply(lambda x: str(x).split()[1] if str(x)!=\"NaT\" else str(x))\n",
    "    \n",
    "    # update table\n",
    "    table_data = df.drop(['stop_id','stop_lat','stop_lon','schedule_id', 'color', 'trip_id'], axis=1)\n",
    "    # output table\n",
    "    table = display(table_data)\n",
    "    \n",
    "    # update figure\n",
    "    with figure.batch_update():\n",
    "        figure.data[0].lat = df[\"stop_lat\"]\n",
    "        figure.data[0].lon = df[\"stop_lon\"]\n",
    "        figure.data[0].text = df[\"stop_name\"]\n",
    "        figure.data[0].marker.color = df['color']\n",
    "        \n",
    "# widget\n",
    "choose_schedule = widgets.Dropdown(options=schedule_list)\n",
    "out = widgets.interactive_output(f, {'a': choose_schedule})\n",
    "\n",
    "# display\n",
    "VBox([choose_schedule, HBox([figure, out])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2cd9de-c443-47c0-871f-3c4143db475b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
